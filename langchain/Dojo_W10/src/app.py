import streamlit as st
from main import load_and_split_file, create_vetordb, get_retriever, get_chain, run_chain

st.set_page_config(
    page_title="ğŸ§  Dojo IA - Q&A sur documents",
    layout="wide"
)

# Page principale
st.title("ğŸ§  Dojo IA - Q/R sur Documents")
question = st.text_input("â“ Posez votre question :")

# Sidebar
with st.sidebar:
    # EntrÃ©e de la clÃ© API
    api_key = st.text_input("ğŸ”‘ Entrez votre clÃ© API:", type="password")
    
    # Upload de fichier(s) - MODIFIÃ‰ pour accepter plusieurs fichiers
    uploaded_files = st.file_uploader(
        "ğŸ“„ Importez un ou plusieurs documents (PDF, DOCX, TXT):", 
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True  # âœ… Permet plusieurs fichiers
    )
    
    # ParamÃ¨tre : chunk size & Nb de documents Ã  rÃ©cuprÃ©rer
    chunk_size = st.slider("ğŸ§© Taille des chunks", 100, 2000, 500, step=100)
    chunk_overlap = st.slider("ğŸ§© Taille des chevauchement", 100, 500, 50, step=50)
    top_k = st.slider("ğŸ“š Nombre de documents Ã  rÃ©cupÃ©rer", 1, 10, 3)

# Initialisation
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if uploaded_files and api_key:
    try:
        # 1. Traitement et vectorisation de TOUS les fichiers
        with st.spinner(f"ğŸ”„ Traitement de {len(uploaded_files)} document(s)..."):
            all_chunks = []
            
            # Traitement de chaque fichier
            for i, uploaded_file in enumerate(uploaded_files, 1):
                st.write(f"ğŸ“„ Traitement du fichier {i}/{len(uploaded_files)}: {uploaded_file.name}")
                chunks = load_and_split_file(uploaded_file, chunk_size, chunk_overlap)
                all_chunks.extend(chunks)  # Ajouter tous les chunks Ã  la liste globale
            
            # CrÃ©er une base vectorielle avec TOUS les chunks
            vectordb = create_vetordb(all_chunks, api_key)
            retriever = get_retriever(vectordb, top_k)
            qa_chain = get_chain(retriever, api_key)
        
        st.success(f"âœ… {len(uploaded_files)} document(s) traitÃ©(s) avec succÃ¨s! ({len(all_chunks)} chunks au total)")
        
        # Afficher les fichiers traitÃ©s
        with st.expander("ğŸ“‹ Fichiers traitÃ©s"):
            for file in uploaded_files:
                st.write(f"â€¢ {file.name}")
        
        # 2. Traitement de la question
        if question:
            with st.spinner("ğŸ¤” Recherche de la rÃ©ponse..."):
                response = run_chain(qa_chain, question)
                st.session_state.chat_history.append((question, response))
    
    except Exception as e:
        st.error(f"âŒ Erreur lors du traitement: {str(e)}")
        st.info("VÃ©rifiez votre clÃ© API et le format de vos documents.")

elif not api_key:
    st.warning("ğŸ”‘ Veuillez entrer votre clÃ© API Mistral dans la barre latÃ©rale.")
elif not uploaded_files:
    st.warning("ğŸ“„ Veuillez tÃ©lÃ©charger un ou plusieurs documents dans la barre latÃ©rale.")

# Afficher de l'historique (ordre inversÃ© - derniÃ¨re question en haut)
if st.session_state.chat_history:
    st.markdown("### ğŸ—‚ï¸ Historique de conversation")
    for q, a in reversed(st.session_state.chat_history):
        with st.container():
            st.markdown(f"**â“ Question:** {q}")
            st.markdown(f"**ğŸ¤– RÃ©ponse:** {a}")
            st.divider()