{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhGuZLvyLsuJ"
      },
      "source": [
        "# Diabetese Detection Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyhj41tmLqKM"
      },
      "source": [
        "This [dataset](https://raw.githubusercontent.com/mansont/datasets-tests/main/diabetese.csv) contains patient data and their diabetese condition: \"1\" they have diabetes, \"0\" they do not have diabetese.\n",
        "\n",
        "\n",
        "Build the following models and compare their performance:\n",
        "* A logistic regression model\n",
        "* A single-layer perceptron model\n",
        "* A multilayer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pjmKh7qnL6Be"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
            "0            6      148         72       35        0  33.6  0.627   50   \n",
            "1            1       85         66       29        0  26.6  0.351   31   \n",
            "2            8      183         64        0        0  23.3  0.672   32   \n",
            "3            1       89         66       23       94  28.1  0.167   21   \n",
            "4            0      137         40       35      168  43.1  2.288   33   \n",
            "\n",
            "   diabetes  \n",
            "0         1  \n",
            "1         0  \n",
            "2         1  \n",
            "3         0  \n",
            "4         1  \n"
          ]
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/mansont/datasets-tests/main/diabetese.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Pretreatment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['diabetes']\n",
        "X = df.drop('diabetes', axis=1)\n",
        "\n",
        "# Standardisation\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Séparation train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Logistic regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Régression Logistique:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.81        99\n",
            "           1       0.65      0.67      0.66        55\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.74      0.73       154\n",
            "weighted avg       0.76      0.75      0.75       154\n",
            "\n",
            "Régression Logistique: 0.75\n"
          ]
        }
      ],
      "source": [
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train, y_train)\n",
        "y_pred_log = log_model.predict(X_test)\n",
        "print(\"Régression Logistique:\")\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "print('Régression Logistique: %.2f' % accuracy_score(y_test, y_pred_log ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. A single-layer perceptron model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perceptron:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.95      0.78        99\n",
            "           1       0.58      0.13      0.21        55\n",
            "\n",
            "    accuracy                           0.66       154\n",
            "   macro avg       0.62      0.54      0.49       154\n",
            "weighted avg       0.63      0.66      0.58       154\n",
            "\n",
            "Perceptron accuracy: 0.66\n"
          ]
        }
      ],
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(X_train, y_train)\n",
        "y_pred_perc = perceptron.predict(X_test)\n",
        "print(\"Perceptron:\")\n",
        "print(classification_report(y_test, y_pred_perc))\n",
        "print('Perceptron accuracy: %.2f' % accuracy_score(y_test, y_pred_perc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. A multilayer perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP (ReLU):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.80        99\n",
            "           1       0.63      0.65      0.64        55\n",
            "\n",
            "    accuracy                           0.74       154\n",
            "   macro avg       0.72      0.72      0.72       154\n",
            "weighted avg       0.74      0.74      0.74       154\n",
            "\n",
            "MLP accuracy: 0.74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "mlp_relu = MLPClassifier(random_state=0)\n",
        "mlp_relu.fit(X_train, y_train)\n",
        "y_pred_mlp_relu = mlp_relu.predict(X_test)\n",
        "print(\"MLP (ReLU):\")\n",
        "print(classification_report(y_test, y_pred_mlp_relu))\n",
        "print('MLP accuracy: %.2f' % accuracy_score(y_test, y_pred_mlp_relu))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVtqSHJgL6hG"
      },
      "source": [
        "### Is there a notable difference in the MLP performance when a ReLU, Sigmoid or SoftMax activation function is used?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S4mWxSy-MAh0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation: relu - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation: logistic - Accuracy: 0.7403\n",
            "Activation: softmax - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for activation in ['relu', 'logistic', 'softmax']:\n",
        "    try:\n",
        "        model = MLPClassifier(random_state=0)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Activation: {activation} - Accuracy: {acc:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur avec {activation} : {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xjhBsPDMA_-"
      },
      "source": [
        "### Does the network performance change when the density (number of neurons) of the hidden layers change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "paUsPljtMISg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structure cachée: (10,) - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structure cachée: (50,) - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structure cachée: (100,) - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Structure cachée: (100, 50) - Accuracy: 0.7403\n",
            "Structure cachée: (100, 100) - Accuracy: 0.7403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/solenedegrutere/Desktop/wild_code/deep learning/deep_learning/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "for size in [(10,), (50,), (100,), (100, 50), (100, 100)]:\n",
        "    model = MLPClassifier(random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Structure cachée: {size} - Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n",
        "- La régression logistique offre une baseline simple et rapide.\n",
        "- Le perceptron est moins performant que le MLP.\n",
        "- Le choix de la fonction d’activation et du nombre de neurones n'impacte pas la performance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (deep_learning)",
      "language": "python",
      "name": "deep_learning"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
